# ======================================
# analyze_routes.py
# ======================================
from flask import Blueprint, request, jsonify
from PIL import Image
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import timm
import exifread
import io

# Tworzymy blueprint Flask
analyze_bp = Blueprint("analyze", __name__)

# ==============================
# ðŸ§  Definicja modelu (CNNEffNetV2)
# ==============================
class CNNEffNetV2(nn.Module):
    def __init__(self, backbone_name="efficientnetv2_rw_m", pretrained=False, num_classes=2):
        super().__init__()
        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0, global_pool='avg')
        in_features = self.backbone.num_features
        self.fc = nn.Linear(in_features, num_classes)

    def forward(self, x):
        features = self.backbone(x)
        out = self.fc(features)
        return out

import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image, ImageFilter
import numpy as np
from flask import Blueprint, request, jsonify
import joblib
import timm # Wymagane dla CNNEffNetV2
import os
from sklearn.ensemble import GradientBoostingClassifier # Zostawiamy importy klas, na wypadek gdyby byÅ‚y potrzebne przez inne moduÅ‚y
from sklearn.svm import SVC 

# UtwÃ³rz Blueprint, jeÅ›li nie byÅ‚ zdefiniowany w innym miejscu
analyze_bp = Blueprint('analyze', __name__) 

# =================================================================
# ARCHITEKTURA I TRANSFORMATOR (Skopiowane z pliku ewaluacyjnego)
# =================================================================

class ResidualTransform:
    """Konwertuje obraz na jego residuum (szum) i normalizuje."""
    def __init__(self, kernel_size=3):
        self.kernel_size = kernel_size
        self.blur_filter = ImageFilter.GaussianBlur(kernel_size)

    def __call__(self, img):
        if not isinstance(img, Image.Image):
            raise TypeError("Obraz musi byÄ‡ typu PIL.Image")

        # Obliczanie residuum: Obraz - Rozmyty obraz
        img_np = np.array(img, dtype=np.float32)
        blurred_img = img.filter(self.blur_filter)
        blurred_np = np.array(blurred_img, dtype=np.float32)

        residual_np = img_np - blurred_np
        residual_norm = np.clip(residual_np + 128, 0, 255).astype(np.uint8)

        return Image.fromarray(residual_norm).convert('RGB')

class CNNEffNetV2(nn.Module):
    def __init__(self, backbone_name="efficientnetv2_rw_m", pretrained=False, num_classes=2):
        super().__init__()
        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0, global_pool='avg')
        in_features = self.backbone.num_features
        self.fc = nn.Linear(in_features, num_classes)

    def forward(self, x):
        features = self.backbone(x)
        out = self.fc(features)
        # Zwracamy predykcjÄ™ (out) i cechy (features)
        return out, features

# =================================================================
# ðŸ”§ ÅADOWANIE MODELI ENSEMBLE (JEDNOKROTNIE PRZY STARCIE)
# Zmieniono logikÄ™: Å‚adujemy tylko CNN i SVM.
# =================================================================

DEVICE = torch.device("cpu") # Zgodnie z Twoim plikiem, uÅ¼ywamy CPU
IMG_SIZE = (320, 320)
NUM_CLASSES = 2

# ÅšcieÅ¼ki do plikÃ³w
CNN_WEIGHTS_FILE = "best_cnn_nua.pth"
SVM_FILE = "re_trained_svm_nua.pkl"
# META_GB_FILE usuniÄ™to

# 1. Åadowanie modelu CNN i wag
try:
    cnn_model = CNNEffNetV2(num_classes=NUM_CLASSES).to(DEVICE)
    cnn_model.load_state_dict(torch.load(CNN_WEIGHTS_FILE, map_location=DEVICE))
    cnn_model.eval()
    print(f"âœ… ZaÅ‚adowano model CNN z: {CNN_WEIGHTS_FILE}")
except Exception as e:
    cnn_model = None
    print(f"âŒ BÅ‚Ä…d Å‚adowania CNN ({CNN_WEIGHTS_FILE}): {e}")

# 2. Åadowanie SVM (Meta-Klasyfikator 1)
try:
    svm_clf = joblib.load(SVM_FILE)
    print(f"âœ… ZaÅ‚adowano model SVM z: {SVM_FILE}")
except Exception as e:
    svm_clf = None
    print(f"âŒ BÅ‚Ä…d Å‚adowania SVM ({SVM_FILE}): {e}")

# Transformacje wejÅ›ciowe (z Residuals)
transform = transforms.Compose([
    transforms.Resize(IMG_SIZE),
    ResidualTransform(kernel_size=3),
    transforms.ToTensor(),
    # UÅ¼ywamy tej samej normalizacji, co w pliku treningowym
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) 
])

# PrÃ³g dla uÅ›rednionej predykcji (moÅ¼na dostosowaÄ‡, np. do 0.5)
BEST_THR = 0.55 

# =================================================================
# ðŸ” Endpoint: analiza NUA (UÅ»YCIE UPROSZCZONEGO ENSEMBLE: CNN + SVM)
# =================================================================

@analyze_bp.route("/nua", methods=["POST"])
def analyze_nua_simplified():
    # Zmieniono warunek sprawdzajÄ…cy zaÅ‚adowanie modeli (tylko CNN i SVM)
    if not all([cnn_model, svm_clf]):
        # Komunikat 503, gdy modele nie sÄ… dostÄ™pne
        return jsonify({"error": "BÅ‚Ä…d: Krytyczne modele CNN lub SVM nie sÄ… zaÅ‚adowane poprawnie na serwerze (bÅ‚Ä…d 503). SprawdÅº logi serwera."}), 503

    if "file" not in request.files:
        return jsonify({"error": "Brak pliku"}), 400

    file = request.files["file"]
    try:
        image = Image.open(file.stream).convert("RGB")
        # Krok 1: Transformacja i przygotowanie tensora
        tensor = transform(image).unsqueeze(0).to(DEVICE)
    except Exception as e:
        return jsonify({"error": f"BÅ‚Ä…d przetwarzania obrazu: {e}"}), 400

    # ------------------
    # FAZA PREDYKCJI UPROSZCZONEGO ENSEMBLE
    # ------------------
    with torch.no_grad():
        # A. CNN: Wykonanie forward pass
        cnn_output, cnn_features = cnn_model(tensor)
        
        # B. CNN: Generowanie prawdopodobieÅ„stwa
        cnn_prob_nua = torch.softmax(cnn_output, dim=1)[0, 1].item()
        
        # C. CNN: Ekstrakcja cech (input dla SVM)
        cnn_features_np = cnn_features.cpu().numpy()
        
    # D. SVM: Generowanie prawdopodobieÅ„stwa
    svm_prob_nua = svm_clf.predict_proba(cnn_features_np)[:, 1][0]
    
    # E. UÅ›rednianie predykcji (zastÄ™puje model Meta-Ensemble)
    ensemble_prob = (cnn_prob_nua + svm_prob_nua) / 2.0
    
    # ------------------
    # WYNIK I KONFIDENCJA
    # ------------------
    prob = max(0.0, min(1.0, ensemble_prob))
    
    threshold = BEST_THR
    detected = prob > threshold
    
    # Obliczenie konfidencji
    k = 1.5
    if prob < threshold:
        # Konfidencja w brak NUA (klasa 0)
        confidence = (threshold - prob) / threshold * 100.0
    else:
        # Konfidencja w obecnoÅ›Ä‡ NUA (klasa 1)
        confidence = (prob - threshold) / (1 - threshold) * 100.0

    confidence = round(confidence * k, 2)
    
    # Zmieniono nazwÄ™ funkcji endpointu z analyze_nua_ensemble na analyze_nua_simplified, 
    # aby odzwierciedliÄ‡ uproszczonÄ… logikÄ™. JeÅ›li uÅ¼ywasz tego endpointu pod adresem /nua, 
    # upewnij siÄ™, Å¼e inne czÄ™Å›ci aplikacji odwoÅ‚ujÄ… siÄ™ do tej nazwy lub pozostaw oryginalnÄ….
    return jsonify({
        "detected": bool(detected),
        "confidence": confidence
    })
# ==============================
# ðŸ§¾ Endpoint: analiza metadanych
# ==============================
@analyze_bp.route("/metadata", methods=["POST"])
def analyze_metadata():
    if "image" not in request.files:
        return jsonify({"error": "No image uploaded"}), 400

    file = request.files["image"]
    file_bytes = file.read()

    # Otwieranie obrazu
    image = Image.open(io.BytesIO(file_bytes))

    # Odczyt EXIF
    file.seek(0)
    exif_tags = exifread.process_file(io.BytesIO(file_bytes), details=False)

    metadata = {
        "File Name": file.filename,
        "Format": image.format or "N/A",
        "Mode": image.mode,
        "Resolution": f"{image.width} x {image.height}",
        "File Size": f"{round(len(file_bytes) / 1024, 2)} KB",
        "EXIF Data": {tag: str(value) for tag, value in exif_tags.items()},
    }

    gps = {k: str(v) for k, v in exif_tags.items() if "GPS" in k}
    metadata["GPS Info"] = gps if gps else "No GPS metadata found"

    return jsonify(metadata)
