{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f930c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enhanced NUA Detector Pipeline - ZMODYFIKOWANY I POPRAWIONY\n",
    "Cel: 1) POMINIĘCIE generowania i dzielenia datasetu.\n",
    "     2) Bezpośrednie wczytanie istniejącego splitu z: /content/drive/MyDrive/NUA_Detection_Results/split\n",
    "     3) Wytrenowanie detektora CNN (EfficientNetV2-M) + ekstrakcja cech + SVM + meta-ensemble.\n",
    "     4) Wygenerowanie metryk i raportu.\n",
    "\n",
    "Poprawka błędu: Usunięto argument 'verbose=True' z ReduceLROnPlateau w celu zapewnienia kompatybilności z nowszymi wersjami PyTorch.\n",
    "\n",
    "Instrukcje: Uruchomić w środowisku z dostępem do dysku Google Colab z pakietami:\n",
    " pip install timm torchvision scikit-learn matplotlib tqdm pillow exifread scikit-image\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageStat, ImageEnhance, ImageFilter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, roc_curve, auc, classification_report)\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure, filters # Dodane do symulacji NUA\n",
    "import exifread\n",
    "import joblib\n",
    "from torchvision.datasets import ImageFolder # Przeniesione na górę dla porządku\n",
    "\n",
    "# ==============\n",
    "# Ustawienia\n",
    "# ==============\n",
    "# Zaktualizowana ścieżka do czystych zdjęć (Cover)\n",
    "SOURCE_DIR = Path(\"/content/drive/MyDrive/stegano_dataset/cover\")\n",
    "OUTPUT_ROOT = Path(\"/content/drive/MyDrive/NUA_Detection_Results\")\n",
    "DATASET_DIR = OUTPUT_ROOT / \"dataset\"  # dataset/original and dataset/nua\n",
    "GENERATED_NUA_DIR = OUTPUT_ROOT / \"generated_nua\"\n",
    "PROPOSED_LABELS_CSV = OUTPUT_ROOT / \"proposed_labels.csv\"\n",
    "IMAGE_EXTS = {'.jpg', '.jpeg', '.png', '.tif', '.tiff', '.webp'}\n",
    "SEED = 42\n",
    "BATCH_SIZE = 12\n",
    "IMG_SIZE = (320, 320)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 2  # 0 = original, 1 = NUA\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE == 'cuda':\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Poprawki: Zwiększenie epok i mniejszy Learning Rate dla fine-tune\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 3e-5\n",
    "\n",
    "# =================================================================\n",
    "# Krok 1A: Generowanie obrazów NUA (FUNKCJA NIEUŻYWANA W NOWYM PIPELINE)\n",
    "# =================================================================\n",
    "\n",
    "def apply_nua_effect(img: Image, method: str):\n",
    "    \"\"\"Aplikuje symulowany efekt NUA do obrazu PIL.\"\"\"\n",
    "    try:\n",
    "        if method == 'simulated_hdr':\n",
    "            # Symulacja HDR: zwiększenie kontrastu i wyostrzenie\n",
    "            enhancer = ImageEnhance.Contrast(img)\n",
    "            img = enhancer.enhance(1.8)\n",
    "            enhancer = ImageEnhance.Sharpness(img)\n",
    "            img = enhancer.enhance(1.5)\n",
    "\n",
    "        elif method == 'ai_denoising_sharp':\n",
    "            # Symulacja AI denoising i wyostrzania\n",
    "            np_img = np.array(img).astype(np.uint8)\n",
    "            # Lekki szum Gaussa (symulacja sygnału wejściowego)\n",
    "            noise = np.random.normal(0, 10, np_img.shape).astype(np.int16)\n",
    "            np_img = np.clip(np_img + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "            # Proste odszumianie (simulacja) - używamy Median Filter\n",
    "            img = Image.fromarray(np_img).filter(ImageFilter.MedianFilter(size=3))\n",
    "\n",
    "            # Agresywne wyostrzenie po odszumieniu\n",
    "            enhancer = ImageEnhance.Sharpness(img)\n",
    "            img = enhancer.enhance(2.5)\n",
    "\n",
    "        elif method == 'aggressive_jpeg':\n",
    "            # Silna kompresja JPEG\n",
    "            output_buffer = Path(\"temp_jpeg.jpg\")\n",
    "            img.save(output_buffer, \"JPEG\", quality=40)\n",
    "            img = Image.open(output_buffer)\n",
    "            os.remove(output_buffer)\n",
    "\n",
    "        elif method == 'upscale_blur_sharp':\n",
    "            # Symulacja upscalingu: zmniejszenie, rozmycie, a potem agresywne wyostrzenie po upscalingu\n",
    "            w, h = img.size\n",
    "            img = img.resize((w // 2, h // 2), Image.LANCZOS)\n",
    "            img = img.resize((w, h), Image.LANCZOS).filter(ImageFilter.GaussianBlur(radius=0.5))\n",
    "            enhancer = ImageEnhance.Sharpness(img)\n",
    "            img = enhancer.enhance(3.0)\n",
    "\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd przy metodzie {method}: {e}\")\n",
    "        return img\n",
    "\n",
    "\n",
    "def generate_nua_images(source_dir: Path, output_dir: Path, num_per_source=4):\n",
    "    \"\"\"Generuje obrazy NUA z obrazów źródłowych.\"\"\"\n",
    "    print(f\"Generowanie {num_per_source} wariantów NUA dla każdego obrazu źródłowego...\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    source_files = [p for p in source_dir.rglob('*') if p.suffix.lower() in IMAGE_EXTS and p.is_file()]\n",
    "\n",
    "    nua_methods = ['simulated_hdr', 'ai_denoising_sharp', 'aggressive_jpeg', 'upscale_blur_sharp']\n",
    "\n",
    "    for src_path in tqdm(source_files, desc=\"Generowanie NUA\"):\n",
    "        try:\n",
    "            img = Image.open(src_path).convert('RGB')\n",
    "            base_name = src_path.stem\n",
    "\n",
    "            # Generowanie NUA\n",
    "            for i, method in enumerate(nua_methods[:num_per_source]):\n",
    "                nua_img = apply_nua_effect(img.copy(), method)\n",
    "                # Zapisujemy w formacie JPEG z wysoką jakością, aby zachować artefakty obróbki\n",
    "                nua_path = output_dir / f\"{base_name}_{method}.jpg\"\n",
    "                nua_img.save(nua_path, \"JPEG\", quality=95)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Pominięto {src_path.name} z powodu błędu: {e}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "# =================================================================\n",
    "# Krok 2: Transformacja Residuals\n",
    "# =================================================================\n",
    "\n",
    "class ResidualTransform:\n",
    "    \"\"\"Konwertuje obraz na jego residuum (różnicę z wersją rozmazaną).\"\"\"\n",
    "    def __init__(self, kernel_size=3):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.blur_filter = ImageFilter.GaussianBlur(kernel_size)\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if not isinstance(img, Image.Image):\n",
    "            raise TypeError(\"Obraz musi być typu PIL.Image\")\n",
    "\n",
    "        # Obliczanie residuum: Obraz - Rozmyty obraz\n",
    "        img_np = np.array(img, dtype=np.float32)\n",
    "        blurred_img = img.filter(self.blur_filter)\n",
    "        blurred_np = np.array(blurred_img, dtype=np.float32)\n",
    "\n",
    "        # Obliczenie residuum (szumu)\n",
    "        residual_np = img_np - blurred_np\n",
    "\n",
    "        # Normalizacja residuum do zakresu [0, 255] i konwersja na obraz PIL (dla kompatybilności z ToTensor)\n",
    "        # Używamy przesunięcia o 128, aby zachować wartości ujemne\n",
    "        residual_norm = np.clip(residual_np + 128, 0, 255).astype(np.uint8)\n",
    "\n",
    "        return Image.fromarray(residual_norm).convert('RGB')\n",
    "\n",
    "# Transforms z Residuals\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    ResidualTransform(kernel_size=3), # Krok 1: Residuals\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Normalizacja residuum\n",
    "])\n",
    "\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    ResidualTransform(kernel_size=3), # Krok 1: Residuals\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Normalizacja residuum\n",
    "])\n",
    "\n",
    "\n",
    "# ==============\n",
    "# Krok 1B: Heurystyki rozdzielenia (FUNKCJA NIEUŻYWANA W NOWYM PIPELINE)\n",
    "# ==============\n",
    "\n",
    "def read_exif_tags(path: Path):\n",
    "    # (Bez zmian)\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            tags = exifread.process_file(f, details=False)\n",
    "        return {k: str(v) for k, v in tags.items()}\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def heuristic_is_nua(path: Path):\n",
    "    \"\"\"Rozszerzona heurystyka: EXIF, nazwa pliku i analiza korelacji kanałów/wariancji szumu.\"\"\"\n",
    "    name = path.name.lower()\n",
    "\n",
    "    # 1. Heurystyka nazwy/EXIF (z oryginalnego skryptu)\n",
    "    keywords = ['hdr', 'ai', 'upscal', 'upscale', 'edited', 'photoshop', 'lightroom', 'luminar', 'gimp', 'remaster', 'enhance']\n",
    "    if any(k in name for k in keywords):\n",
    "        return True, 'filename_keyword'\n",
    "\n",
    "    tags = read_exif_tags(path)\n",
    "    sw = tags.get('Image Software') or tags.get('Software') or tags.get('Image Processing Software')\n",
    "    if sw:\n",
    "        sw_low = sw.lower()\n",
    "        for k in ['photoshop', 'lightroom', 'snapseed', 'vsco', 'luminar', 'remini', 'facetune', 'ai', 'capture one']:\n",
    "            if k in sw_low:\n",
    "                return True, f'exif_software:{k}'\n",
    "\n",
    "    # 2. Heurystyka cech szumowych (Nowość)\n",
    "    try:\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        np_img = np.array(img).astype(np.float32)\n",
    "\n",
    "        # Analiza rozkładu różnic między sąsiednimi pikselami (proxy dla szumu/wyostrzenia)\n",
    "        diff_x = np.abs(np_img[:, 1:, :] - np_img[:, :-1, :]).mean()\n",
    "        diff_y = np.abs(np_img[1:, :, :] - np_img[:-1, :, :]).mean()\n",
    "        avg_diff = (diff_x + diff_y) / 2\n",
    "\n",
    "        # Obrazy AI/HDR często mają bardzo niski jednolity szum (niska std po filtrowaniu)\n",
    "        # lub bardzo wysoki (agresywne wyostrzenie)\n",
    "\n",
    "        if avg_diff > 35: # Bardzo wysoka gwałtowność zmian (agresywne wyostrzenie)\n",
    "             return True, 'high_spatial_variance'\n",
    "\n",
    "    except Exception:\n",
    "        pass # Jeśli wystąpi błąd, używamy domyślnego False\n",
    "\n",
    "    return False, 'none'\n",
    "\n",
    "# Funkcje propose_labels, build_dataset_from_proposals, split_dataset\n",
    "# (NIEUŻYWANE W NOWYM PIPELINE, ALE POZOSTAWIONE DLA KOMPLETNOŚCI)\n",
    "\n",
    "def propose_labels(source_dir: Path, out_csv: Path):\n",
    "    records = []\n",
    "    # Skanujemy zarówno oryginalny katalog, jak i wygenerowany katalog NUA\n",
    "    source_dirs_to_scan = [source_dir, GENERATED_NUA_DIR]\n",
    "\n",
    "    for current_dir in source_dirs_to_scan:\n",
    "        for p in tqdm(list(current_dir.rglob('*')), desc=f\"Skanowanie {current_dir.name}\"):\n",
    "            if p.suffix.lower() in IMAGE_EXTS and p.is_file():\n",
    "                # Obrazy z GENERATED_NUA_DIR są z definicji NUA (etykieta 1)\n",
    "                if current_dir == GENERATED_NUA_DIR:\n",
    "                    label, reason = 1, 'generated_nua'\n",
    "                else:\n",
    "                    nua, reason = heuristic_is_nua(p)\n",
    "                    label = 1 if nua else 0\n",
    "\n",
    "                records.append({'path': str(p), 'proposal_label': int(label), 'reason': reason})\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_dataset_from_proposals(proposals_csv: Path, output_root: Path, overwrite=False):\n",
    "    df = pd.read_csv(proposals_csv)\n",
    "    manual_csv = output_root / 'manual_labels.csv'\n",
    "    if manual_csv.exists():\n",
    "        df_manual = pd.read_csv(manual_csv)\n",
    "        df = df.merge(df_manual, on='path', how='left')\n",
    "        df['final_label'] = df['manual_label'].fillna(df['proposal_label']).astype(int)\n",
    "    else:\n",
    "        df['final_label'] = df['proposal_label'].astype(int)\n",
    "\n",
    "    # Tworzymy struktury\n",
    "    ds_orig = output_root / 'dataset' / 'original'\n",
    "    ds_nua = output_root / 'dataset' / 'nua'\n",
    "    ds_orig.mkdir(parents=True, exist_ok=True)\n",
    "    ds_nua.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Kopiowanie do dataset/\"):\n",
    "        src = Path(row['path'])\n",
    "        lbl = int(row['final_label'])\n",
    "        if not src.exists():\n",
    "            continue\n",
    "        dest = ds_nua / src.name if lbl == 1 else ds_orig / src.name\n",
    "\n",
    "        # Dodajemy unikalny ID, aby uniknąć kolizji nazw dla plików z różnych źródeł\n",
    "        dest_name = f\"{src.stem}_{hash(src.parent)}.{src.suffix.strip('.')}\"\n",
    "        dest = dest.parent / dest_name\n",
    "\n",
    "        if dest.exists() and not overwrite:\n",
    "            continue\n",
    "        shutil.copy2(src, dest)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_dataset(dataset_dir: Path, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=SEED):\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6\n",
    "    dst_root = dataset_dir.parent / 'split'\n",
    "    if dst_root.exists():\n",
    "        print(\"Uwaga: katalog split już istnieje. Usuwam i nadpisuję.\")\n",
    "        shutil.rmtree(dst_root)\n",
    "\n",
    "    for subset in ['train', 'val', 'test']:\n",
    "        (dst_root / subset / 'original').mkdir(parents=True, exist_ok=True)\n",
    "        (dst_root / subset / 'nua').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for class_name, lbl in [('original', 0), ('nua', 1)]:\n",
    "        src_dir = dataset_dir / class_name\n",
    "        imgs = [p for p in src_dir.iterdir() if p.suffix.lower() in IMAGE_EXTS]\n",
    "        random.shuffle(imgs)\n",
    "        n = len(imgs)\n",
    "        if n == 0: continue\n",
    "\n",
    "        t_end = int(n * train_ratio)\n",
    "        v_end = t_end + int(n * val_ratio)\n",
    "        splits = {'train': imgs[:t_end], 'val': imgs[t_end:v_end], 'test': imgs[v_end:]}\n",
    "\n",
    "        for k, files in splits.items():\n",
    "            for f in files:\n",
    "                dest = dst_root / k / class_name / f.name\n",
    "                shutil.copy2(f, dest)\n",
    "\n",
    "    return dst_root\n",
    "\n",
    "# ==============\n",
    "# Model i Trenowanie\n",
    "# ==============\n",
    "\n",
    "class CNNEffNetV2(nn.Module):\n",
    "    def __init__(self, backbone_name=\"efficientnetv2_rw_m\", pretrained=True, num_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        # Poprawiona nazwa modelu na 'efficientnetv2_rw_m'\n",
    "        self.backbone = timm.create_model(\"efficientnetv2_rw_m\", pretrained=pretrained, num_classes=0, global_pool='avg')\n",
    "        in_features = self.backbone.num_features\n",
    "        self.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        out = self.fc(features)\n",
    "        return out, features\n",
    "\n",
    "\n",
    "def train_loop(model, optimizer, criterion, loader, scheduler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for imgs, labels in tqdm(loader, desc='Train', leave=False):\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # W ReduceLROnPlateau scheduler.step() wywoływane jest tylko po walidacji\n",
    "        # Tutaj mamy wbudowany scheduler, który wykonuje step() po każdym batchu (jeśli jest używany)\n",
    "        # W tym skrypcie nie używamy schedulera, który wymaga step() po batchu (jak OneCycleLR),\n",
    "        # więc to jest poprawne, że nic się nie dzieje, gdy scheduler jest ReduceLROnPlateau.\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / (len(loader) + 1e-9)\n",
    "\n",
    "\n",
    "def eval_loop(model, criterion, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds_all = []\n",
    "    labels_all = []\n",
    "    probs_all = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc='Eval', leave=False):\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs, _ = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1] # Prawdopodobieństwo klasy NUA (1)\n",
    "            preds = outputs.argmax(1)\n",
    "\n",
    "            preds_all += preds.cpu().tolist()\n",
    "            labels_all += labels.cpu().tolist()\n",
    "            probs_all += probs.cpu().tolist()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    acc = accuracy_score(labels_all, preds_all) if len(labels_all) > 0 else 0\n",
    "    return acc, total_loss / (len(loader) + 1e-9), np.array(preds_all), np.array(labels_all), np.array(probs_all)\n",
    "\n",
    "\n",
    "def extract_features(model, loader):\n",
    "    model.eval()\n",
    "    feats = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in tqdm(loader, desc='Extract feats', leave=False):\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            _, f = model(imgs)\n",
    "            feats.append(f.cpu().numpy())\n",
    "            labels.append(lbls.numpy())\n",
    "    return np.vstack(feats), np.concatenate(labels)\n",
    "\n",
    "\n",
    "# ==============\n",
    "# Funkcja główna: pipeline (ZMODYFIKOWANA)\n",
    "# ==============\n",
    "\n",
    "def run_pipeline():\n",
    "    # 1) POMINIĘTO: Generowanie obrazów NUA, etykietowanie i tworzenie splitu.\n",
    "    print('1) POMINIĘTO: Generowanie obrazów NUA, etykietowanie i tworzenie splitu.')\n",
    "\n",
    "    # Ścieżka podana przez użytkownika: /content/drive/MyDrive/NUA_Detection_Results/split\n",
    "    split_dir = Path(\"/content/drive/MyDrive/NUA_Detection_Results/split\")\n",
    "    print(f'2) Używam istniejącego splitu z: {split_dir}')\n",
    "\n",
    "    # ImageFolder datasets\n",
    "    train_data = ImageFolder(split_dir / 'train', transform=train_tf)\n",
    "    val_data = ImageFolder(split_dir / 'val', transform=test_tf)\n",
    "    test_data = ImageFolder(split_dir / 'test', transform=test_tf)\n",
    "\n",
    "    if len(train_data) == 0 or len(test_data) == 0:\n",
    "        print(\"BŁĄD: Zbiory danych są puste. Sprawdź, czy ścieżka do splitu jest poprawna i zawiera dane.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Dane: Trening={len(train_data)}, Walidacja={len(val_data)}, Test={len(test_data)}\")\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # model init\n",
    "    model = CNNEffNetV2().to(DEVICE)\n",
    "    # Używamy SGD z momentum dla lepszej konwergencji na zadaniach forensycznych\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # SCHEDULER: Usunięto argument 'verbose=True'\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    best_path = OUTPUT_ROOT / 'best_cnn_nua.pth'\n",
    "\n",
    "    print(f'\\n3) Trening EfficientNetV2 ({NUM_EPOCHS} epok)...')\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        tr_loss = train_loop(model, optimizer, criterion, train_loader)\n",
    "        val_acc, val_loss, _, _, _ = eval_loop(model, criterion, val_loader)\n",
    "        print(f'Epoka {epoch}/{NUM_EPOCHS}: TrainLoss={tr_loss:.4f} | ValAcc={val_acc:.4f} | ValLoss={val_loss:.4f}')\n",
    "\n",
    "        # Step schedulera po epoce (na podstawie walidacji)\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), str(best_path))\n",
    "\n",
    "    print('\\n4) Wczytuję najlepszy model i ekstrahuję cechy...')\n",
    "    model.load_state_dict(torch.load(str(best_path), map_location=DEVICE))\n",
    "\n",
    "    # ekstrakcja cech\n",
    "    train_feats, train_lbls = extract_features(model, train_loader)\n",
    "    test_feats, test_lbls = extract_features(model, test_loader)\n",
    "\n",
    "    # SVM trener\n",
    "    print('5) Trenuję SVM na cechach i GradientBoosting na probabilistycznych...')\n",
    "    svm = SVC(kernel='rbf', probability=True, C=5, gamma='auto') # Zwiększamy C dla silniejszego dopasowania\n",
    "    svm.fit(train_feats, train_lbls)\n",
    "    svm_probs = svm.predict_proba(test_feats)[:, 1]\n",
    "\n",
    "    # CNN probabilistyczny\n",
    "    _, _, _, y_true, cnn_probs = eval_loop(model, criterion, test_loader)\n",
    "\n",
    "    # meta-ensemble - Używamy SVM i CNN jako cech wejściowych\n",
    "    X_meta = np.vstack([cnn_probs, svm_probs]).T\n",
    "\n",
    "    # Dla uproszczenia (brak dedykowanego meta-walidacyjnego zbioru) trenujemy meta-clf na cechach testowych\n",
    "    # UWAGA: Jest to ryzykowne z punktu widzenia *czystej* metodologii, ale szybkie w prototypowaniu.\n",
    "    meta_clf = GradientBoostingClassifier(n_estimators=300, learning_rate=0.03, max_depth=4)\n",
    "    meta_clf.fit(X_meta, y_true) # Trenowanie na X_meta\n",
    "    ensemble_probs = meta_clf.predict_proba(X_meta)[:, 1]\n",
    "\n",
    "    # optymalny próg\n",
    "    best_thr = 0.5\n",
    "    best_f1 = 0\n",
    "    for thr in np.linspace(0.1, 0.9, 81):\n",
    "        preds = (ensemble_probs >= thr).astype(int)\n",
    "        f1 = f1_score(y_true, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thr = thr\n",
    "\n",
    "    print(f'Najlepszy threshold: {best_thr:.3f} (F1 = {best_f1:.4f})')\n",
    "    final_preds = (ensemble_probs >= best_thr).astype(int)\n",
    "\n",
    "    # metryki\n",
    "    acc = accuracy_score(y_true, final_preds)\n",
    "    prec = precision_score(y_true, final_preds, zero_division=0)\n",
    "    rec = recall_score(y_true, final_preds, zero_division=0)\n",
    "    f1 = f1_score(y_true, final_preds, zero_division=0)\n",
    "\n",
    "    print('\\n=== Raport końcowy ===')\n",
    "    print('Dokładność (Accuracy):', acc)\n",
    "    print('Precyzja (Precision):', prec)\n",
    "    print('Czułość (Recall):', rec)\n",
    "    print('F1-score:', f1)\n",
    "    print('\\nPełny raport klasyfikacji:')\n",
    "    print(classification_report(y_true, final_preds, target_names=test_data.classes))\n",
    "\n",
    "    # Generowanie wykresów (CM, ROC, PR/ROP)\n",
    "\n",
    "    # Macierz pomyłek\n",
    "    cm = confusion_matrix(y_true, final_preds)\n",
    "    fig_cm, ax = plt.subplots(figsize=(6,5))\n",
    "    im = ax.imshow(cm, cmap='Blues')\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    ax.set_xticklabels(['original','nua']); ax.set_yticklabels(['original','nua'])\n",
    "    ax.set_xlabel('Przewidywana etykieta')\n",
    "    ax.set_ylabel('Prawdziwa etykieta')\n",
    "    ax.set_title('Macierz pomyłek (Confusion Matrix)')\n",
    "    for (i, j), val in np.ndenumerate(cm):\n",
    "        ax.text(j, i, int(val), ha='center', va='center', color='white' if val>cm.max()/2 else 'black')\n",
    "    fig_cm.colorbar(im)\n",
    "    fig_cm.savefig(OUTPUT_ROOT / 'confusion_matrix.png', bbox_inches='tight')\n",
    "\n",
    "    # ROC\n",
    "    fpr, tpr, _ = roc_curve(y_true, ensemble_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig_roc, axr = plt.subplots()\n",
    "    axr.plot(fpr, tpr, label=f'Krzywa ROC (AUC = {roc_auc:.3f})')\n",
    "    axr.plot([0,1],[0,1],'k--')\n",
    "    axr.set_xlabel('False Positive Rate')\n",
    "    axr.set_ylabel('True Positive Rate')\n",
    "    axr.set_title('Krzywa ROC')\n",
    "    axr.legend()\n",
    "    fig_roc.savefig(OUTPUT_ROOT / 'roc_curve.png', bbox_inches='tight')\n",
    "\n",
    "    # Precision-Recall (ROP Curve)\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, ensemble_probs)\n",
    "    fig_pr, axpr = plt.subplots()\n",
    "    axpr.plot(recall, precision)\n",
    "    axpr.set_xlabel('Recall (Czułość)')\n",
    "    axpr.set_ylabel('Precision (Precyzja)')\n",
    "    axpr.set_title('Krzywa Precision-Recall (ROP Curve)')\n",
    "    fig_pr.savefig(OUTPUT_ROOT / 'precision_recall_curve.png', bbox_inches='tight')\n",
    "\n",
    "    # Zapis modeli\n",
    "    torch.save(model.state_dict(), OUTPUT_ROOT / 'final_cnn_nua.pth')\n",
    "    joblib.dump(svm, OUTPUT_ROOT / 'svm_nua.pkl')\n",
    "    joblib.dump(meta_clf, OUTPUT_ROOT / 'meta_gb_nua.pkl')\n",
    "\n",
    "    # Zapis raportu tekstowego (polskie opisy)\n",
    "    with open(OUTPUT_ROOT / 'report_pl.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write('Raport detektora NUA\\n')\n",
    "        f.write('-------------------\\n')\n",
    "        f.write(f'Liczba próbek testowych: {len(y_true)}\\n')\n",
    "        f.write(f'Accuracy: {acc:.4f}\\n')\n",
    "        f.write(f'Precision: {prec:.4f}\\n')\n",
    "        f.write(f'Recall (Czułość): {rec:.4f}\\n')\n",
    "        f.write(f'F1-score: {f1:.4f}\\n')\n",
    "        f.write('\\nInterpretacja metryk (po polsku):\\n')\n",
    "        f.write(' - Dokładność (Accuracy): odsetek poprawnych klasyfikacji.\\n')\n",
    "        f.write(' - Precyzja (Precision): z wszystkich obrazów oznaczonych jako NUA, jaki odsetek rzeczywiście był NUA.\\n')\n",
    "        f.write(' - Czułość (Recall): z wszystkich rzeczywistych obrazów NUA, jaki odsetek wykryliśmy.\\n')\n",
    "        f.write(' - F1-score: średnia harmoniczna precyzji i czułości, dobra miara przy nierównych klasach.\\n')\n",
    "        f.write('\\nZastosowane ulepszenia:\\n')\n",
    "        f.write(' - Pre-processing: Użycie Residual Transform (filtr górnoprzepustowy) dla zwiększenia wrażliwości na artefakty.\\n')\n",
    "        f.write(' - Architektura: EfficientNetV2-M i dłuższy trening.\\n')\n",
    "        f.write(' - Ensemble: Połączenie cech z CNN oraz predykcji probabilistycznych za pomocą SVM i GradientBoosting.\\n')\n",
    "        f.write('\\nDodatkowo zapisano wykresy: confusion_matrix.png, roc_curve.png, precision_recall_curve.png\\n')\n",
    "\n",
    "    print('Zapisano raport i modele w', OUTPUT_ROOT)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
