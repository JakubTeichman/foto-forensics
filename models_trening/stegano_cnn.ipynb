{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ae75d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# STEGANALOG: Trainer - naukowo zgodna wersja (zoptymalizowana pod kÄ…tem prÄ™dkoÅ›ci)\n",
    "# Optymalizacje: Warstwa SRM, szybsza obsÅ‚uga JPEG Augmentation (w pamiÄ™ci), wiÄ™cej workerÃ³w DataLoader.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import io # Dodane dla szybkiego I/O w pamiÄ™ci (JPEG Augmentation)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL.PngImagePlugin import PngInfo\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# ========== USTAWIENIA ======\n",
    "# ============================\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Ustawienie liczby workerÃ³w na podstawie dostÄ™pnych rdzeni CPU (maks. 4 w Colab, by uniknÄ…Ä‡ problemÃ³w)\n",
    "# Zmienione z 2 na 4 dla lepszej wydajnoÅ›ci wczytywania\n",
    "NUM_WORKERS = 4 if DEVICE == \"cuda\" else 0\n",
    "print(\"UrzÄ…dzenie:\", DEVICE)\n",
    "\n",
    "# ÅšcieÅ¼ki â€” dostosuj do wÅ‚asnego Drive\n",
    "DATA_DIR = Path(\"/content/drive/MyDrive/stegano_dataset\")\n",
    "OUTPUT_DIR = Path(\"/content/drive/MyDrive/stegano_dataset/results_sci_optimized\")\n",
    "MY_SOURCE_FOLDER = Path(\"/content/drive/MyDrive/MY_IPHONE_DATASET\") # Opcjonalnie (juÅ¼ nie uÅ¼ywane)\n",
    "\n",
    "for p in (DATA_DIR, OUTPUT_DIR):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Data:\", DATA_DIR, \"Output:\", OUTPUT_DIR)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 2\n",
    "EPOCHS = 12\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "IMG_SIZE = 256 # rozmiar wejÅ›ciowy (zachowany 256)\n",
    "USE_MIXUP = True\n",
    "USE_JPEG_AUG = True  # podczas treningu losowe QF (imitacja post-processingu)\n",
    "SVM_C = 3.0\n",
    "\n",
    "# ============================\n",
    "# ======= STEG GENERATOR =====\n",
    "# (Funkcje pomocnicze, nie uÅ¼ywane w gÅ‚Ã³wnym treningu)\n",
    "# ============================\n",
    "def hide_lsb_image(img: Image.Image, message: str = \"secret\"):\n",
    "    # proste LSB w kanale R\n",
    "    img = img.convert(\"RGB\")\n",
    "    arr = np.array(img, dtype=np.uint8)\n",
    "    bin_msg = ''.join(format(ord(c), '08b') for c in message)\n",
    "    flat = arr[:, :, 0].flatten()\n",
    "    n = min(len(bin_msg), flat.size)\n",
    "    for i in range(n):\n",
    "        flat[i] = (flat[i] & ~1) | int(bin_msg[i])\n",
    "    arr[:, :, 0] = flat.reshape(arr.shape[0], arr.shape[1])\n",
    "    return Image.fromarray(arr)\n",
    "\n",
    "def hide_dct_jpeg(in_path: str, out_path: str, quality: int = 40):\n",
    "    # zapisz jako JPEG z niskÄ… jakoÅ›ciÄ… (symulacja DCT-based steg)\n",
    "    img = cv2.imread(in_path)\n",
    "    if img is None:\n",
    "        return False\n",
    "    cv2.imwrite(str(out_path), img, [int(cv2.IMWRITE_JPEG_QUALITY), quality])\n",
    "    return True\n",
    "\n",
    "def hide_meta_png(src_path: str, out_path: str, comment: str = \"stegano_demo\"):\n",
    "    img = Image.open(src_path)\n",
    "    pnginfo = PngInfo()\n",
    "    pnginfo.add_text(\"comment\", comment)\n",
    "    img.save(out_path, \"PNG\", pnginfo=pnginfo)\n",
    "\n",
    "def generate_stegano_from_file(src_path: Path, dest_path: Path):\n",
    "    method = random.choice([\"lsb\", \"dct\", \"meta\"])\n",
    "    if method == \"lsb\":\n",
    "        img = Image.open(src_path)\n",
    "        steg = hide_lsb_image(img, message=\"HiddenByUser\")\n",
    "        steg.save(dest_path)\n",
    "    elif method == \"dct\":\n",
    "        # uÅ¼yj tymczasowego pliku\n",
    "        hide_dct_jpeg(str(src_path), str(dest_path), quality=random.randint(30,60))\n",
    "    else:\n",
    "        hide_meta_png(str(src_path), str(dest_path))\n",
    "    return method\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ===== DATALOADER I TRANSFORMS =\n",
    "# ============================\n",
    "# Transformacje obrazu (augmentacje)\n",
    "train_tf_img = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(0.05,0.05,0.05,0.02),\n",
    "])\n",
    "\n",
    "val_tf_img = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "])\n",
    "\n",
    "# Normalizacja (ToTensor + Normalize)\n",
    "to_tensor_norm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# Kompletne pipeline transformacji\n",
    "train_transform = transforms.Compose([train_tf_img, to_tensor_norm])\n",
    "val_transform = transforms.Compose([val_tf_img, to_tensor_norm])\n",
    "\n",
    "\n",
    "# Dataset dostosowany do nowej struktury katalogÃ³w i aug. JPEG\n",
    "class SteganoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples, transform=None, jpeg_q_aug=False):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "        self.jpeg_q_aug = jpeg_q_aug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # ðŸ”¥ OPTYMALIZACJA: Szybszy JPEG Augmentation w pamiÄ™ci (bez I/O na dysku)\n",
    "        if self.jpeg_q_aug and random.random() < 0.5:\n",
    "            q = random.randint(30,95)\n",
    "            # UÅ¼ycie io.BytesIO do zapisu/odczytu w pamiÄ™ci\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, \"JPEG\", quality=q)\n",
    "            buffer.seek(0)\n",
    "            img = Image.open(buffer).convert(\"RGB\") # Wczytaj ponownie z bufora\n",
    "            buffer.close()\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# ==============================================\n",
    "# ðŸ“‚ WCZYTYWANIE I BALANSOWANIE DANYCH\n",
    "# ==============================================\n",
    "# Sprawdzenie istnienia folderÃ³w\n",
    "cover_dir = DATA_DIR / \"cover\"\n",
    "pseudo_dir = DATA_DIR / \"pseudo\"\n",
    "stego_dir = DATA_DIR / \"stego\"\n",
    "\n",
    "if not (cover_dir.exists() and pseudo_dir.exists() and stego_dir.exists()):\n",
    "    raise FileNotFoundError(f\"Brak wymaganych folderÃ³w (cover/pseudo/stego) w {DATA_DIR}\")\n",
    "\n",
    "# ðŸ”¥ Wczytanie Å›cieÅ¼ek\n",
    "cover_files = list(cover_dir.rglob(\"*.*\"))\n",
    "pseudo_files = list(pseudo_dir.rglob(\"*.*\"))\n",
    "stego_files = list(stego_dir.rglob(\"*.*\"))\n",
    "\n",
    "# Odsianie plikÃ³w, ktÃ³re nie sÄ… obrazami\n",
    "def filter_images(files):\n",
    "    return [p for p in files if p.suffix.lower() in (\".jpg\", \".jpeg\", \".png\", \".bmp\")]\n",
    "\n",
    "cover_files = filter_images(cover_files)\n",
    "pseudo_files = filter_images(pseudo_files)\n",
    "stego_files = filter_images(stego_files)\n",
    "\n",
    "# âš–ï¸ BALANSOWANIE DANYCH\n",
    "zero_class = cover_files + pseudo_files # label 0\n",
    "one_class = stego_files # label 1\n",
    "\n",
    "print(f\"ZERO (cover+pseudo): {len(zero_class)}\")\n",
    "print(f\"ONE (stego): {len(one_class)}\")\n",
    "\n",
    "# Maksymalna liczba prÃ³bek 0 = 2 Ã— liczba stego (delikatne balansowanie)\n",
    "max_zero = min(len(zero_class), len(one_class) * 2)\n",
    "\n",
    "random.shuffle(zero_class)\n",
    "zero_class = zero_class[:max_zero]\n",
    "\n",
    "print(f\"ZERO (after balancing): {len(zero_class)}\")\n",
    "print(f\"Total samples: {len(zero_class) + len(one_class)}\")\n",
    "\n",
    "# ðŸ”§ Tworzymy listÄ™ (plik, label)\n",
    "all_samples = [(str(p), 0) for p in zero_class] + [(str(p), 1) for p in one_class]\n",
    "random.shuffle(all_samples)\n",
    "\n",
    "\n",
    "# âœ‚ï¸ Split: 70/15/15 ze stratyfikacjÄ…\n",
    "# PoniewaÅ¼ 'all_samples' jest listÄ… Å›cieÅ¼ek, musimy najpierw wydobyÄ‡ etykiety\n",
    "labels = [s[1] for s in all_samples]\n",
    "indices = list(range(len(all_samples)))\n",
    "\n",
    "train_idx, temp_idx = train_test_split(indices, test_size=0.30, stratify=labels, random_state=SEED)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=np.array(labels)[temp_idx], random_state=SEED)\n",
    "\n",
    "train_samples = [all_samples[i] for i in train_idx]\n",
    "val_samples = [all_samples[i] for i in val_idx]\n",
    "test_samples = [all_samples[i] for i in test_idx]\n",
    "\n",
    "# Tworzenie datasetÃ³w\n",
    "train_ds = SteganoDataset(train_samples, transform=train_transform, jpeg_q_aug=USE_JPEG_AUG)\n",
    "val_ds = SteganoDataset(val_samples, transform=val_transform, jpeg_q_aug=False)\n",
    "test_ds = SteganoDataset(test_samples, transform=val_transform, jpeg_q_aug=False)\n",
    "\n",
    "# ðŸ”¥ UÅ¼ycie NUM_WORKERS dla lepszej wydajnoÅ›ci wczytywania danych\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"Split sizes: train\", len(train_ds), \"val\", len(val_ds), \"test\", len(test_ds))\n",
    "\n",
    "# ============================\n",
    "# ===== High-pass (SRM) LAYER =\n",
    "# ============================\n",
    "class SRMLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Warstwa z kilkoma staÅ‚ymi filtrami gÃ³rnoprzepustowymi (uproszczenie SRM).\n",
    "    Zoptymalizowana do uÅ¼ycia jednej konwolucji grupowanej, co jest szybsze.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        # PrzykÅ‚adowe filtry (3x3 / 5x5) - uproszczone SRM-like\n",
    "        kv = np.array([[0, -1, 0],\n",
    "                       [-1, 4, -1],\n",
    "                       [0, -1, 0]], dtype=np.float32) # laplacian-like\n",
    "        kv3 = np.array([[-1, 2, -1],\n",
    "                         [2, -4, 2],\n",
    "                         [-1, 2, -1]], dtype=np.float32) # Drugi filtr\n",
    "\n",
    "        kernels = [kv, kv3]\n",
    "\n",
    "        # ðŸ”¥ OPTYMALIZACJA: Tworzenie pojedynczego tensora wag dla konwolucji grupowej\n",
    "        conv_kernels_list = []\n",
    "        for k in kernels:\n",
    "            k = torch.from_numpy(k).float().unsqueeze(0).unsqueeze(0) # 1x1xHxW\n",
    "            conv_kernels_list.append(k)\n",
    "\n",
    "        # Skonkatenuj filtry i powtÃ³rz dla kaÅ¼dego kanaÅ‚u wejÅ›ciowego\n",
    "        # final_weight shape: (C * n_kernels, 1, kH, kW)\n",
    "        weight_per_channel = torch.cat(conv_kernels_list, dim=0) # n_kernels x 1 x kH x kW\n",
    "\n",
    "        # PowtÃ³rz dla kaÅ¼dego kanaÅ‚u wejÅ›ciowego (depthwise style: in_ch=1)\n",
    "        final_weight = weight_per_channel.repeat(in_channels, 1, 1, 1)\n",
    "\n",
    "        self.register_buffer('kernels', final_weight)\n",
    "        self.in_channels = in_channels\n",
    "        self.n_kernels = len(kernels)\n",
    "        self.out_channels = in_channels * self.n_kernels\n",
    "        self.kernel_size = kernels[0].shape[0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: B x C x H x W\n",
    "        weight = self.kernels.to(x.device)\n",
    "        padding = self.kernel_size // 2\n",
    "\n",
    "        # ðŸ”¥ OPTYMALIZACJA: UÅ¼ycie jednej konwolucji grupowej (depthwise)\n",
    "        # groups=C - dla kaÅ¼dej grupy (kanaÅ‚u wejÅ›ciowego) stosowane jest n_kernels filtrÃ³w\n",
    "        out = F.conv2d(x, weight, padding=padding, groups=self.in_channels)\n",
    "\n",
    "        return torch.tanh(out)\n",
    "\n",
    "# ============================\n",
    "# ======= SRNet-like CNN ======\n",
    "# ============================\n",
    "# Prosty residual-focused CNN (inspiracja SRNet/Yedroudj) - pracuje na residualu (wyjÅ›ciu SRMLayer)\n",
    "class SimpleStegNet(nn.Module):\n",
    "    def __init__(self, in_channels=6, num_classes=2, feature_dim=512):\n",
    "        \"\"\"\n",
    "        in_channels: liczba kanaÅ‚Ã³w wejÅ›ciowych (np. C * n_kernels)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.res_block1 = self._make_res_block(64, 128)\n",
    "        self.res_block2 = self._make_res_block(128, 256)\n",
    "        self.res_block3 = self._make_res_block(256, 512)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512, feature_dim)\n",
    "        self.classifier = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "        # Zmiana: uÅ¼ycie MaxPool zamiast AvgPool na koÅ„cu bloku dla lepszej detekcji lokalnych cech\n",
    "        self.res_block1 = self._make_res_block(64, 128)\n",
    "        self.res_block2 = self._make_res_block(128, 256)\n",
    "        self.res_block3 = self._make_res_block(256, 512)\n",
    "\n",
    "    def _make_res_block(self, in_ch, out_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2) # Zmiana z AvgPool2d na MaxPool2d - moÅ¼e daÄ‡ lepsze wyniki\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x expected residual map (B x in_channels x H x W)\n",
    "        x = self.conv1(x)\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        x = self.pool(x).view(x.size(0), -1)\n",
    "        feats = self.fc(x)\n",
    "        logits = self.classifier(feats)\n",
    "        return logits, feats\n",
    "\n",
    "# PeÅ‚ny model: SRM layer + SRNet\n",
    "class FullStegModel(nn.Module):\n",
    "    def __init__(self, in_rgb_channels=3, num_classes=2, feature_dim=512):\n",
    "        super().__init__()\n",
    "        self.srm = SRMLayer(in_channels=in_rgb_channels)\n",
    "        # SRMLayer produces C * nk channels; nk=2 here => 3*2=6\n",
    "        self.net = SimpleStegNet(in_channels=in_rgb_channels * 2, num_classes=num_classes, feature_dim=feature_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input x: B x 3 x H x W (normalized floats)\n",
    "        residual = self.srm(x) # B x (C*nk) x H x W\n",
    "        logits, feats = self.net(residual)\n",
    "        return logits, feats\n",
    "\n",
    "# ============================\n",
    "# ====== UTILITY: mixup ======\n",
    "# ============================\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    if alpha <= 0:\n",
    "        return x, y, None, None, 1.0\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    index = torch.randperm(x.size(0)).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, index, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# ============================\n",
    "# ===== TRAIN / EVAL (PÅEÄ†) =\n",
    "# ============================\n",
    "model = FullStegModel(in_rgb_channels=3, num_classes=NUM_CLASSES, feature_dim=512).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "# Zmniejszono cierpliwoÅ›Ä‡ dla szybszego uczenia\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, use_mixup=False):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Dodano torch.autocast dla operacji na GPU (FP16 dla przyspieszenia)\n",
    "    scaler = torch.cuda.amp.GradScaler() if DEVICE == \"cuda\" else None\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if DEVICE == \"cuda\":\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if use_mixup:\n",
    "                    imgs_m, y_a, y_b, idx, lam = mixup_data(imgs, labels)\n",
    "                    outputs, _ = model(imgs_m)\n",
    "                    loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "                else:\n",
    "                    outputs, _ = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else: # CPU Path\n",
    "            if use_mixup:\n",
    "                imgs_m, y_a, y_b, idx, lam = mixup_data(imgs, labels)\n",
    "                outputs, _ = model(imgs_m)\n",
    "                loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
    "            else:\n",
    "                outputs, _ = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(1)\n",
    "        # Liczenie poprawnych dla celÃ³w logowania\n",
    "        if use_mixup:\n",
    "            # W przypadku mixup dokÅ‚adnoÅ›Ä‡ jest mniej wiarygodna, ale liczymy jÄ… w uproszczeniu\n",
    "            correct += (preds == labels).sum().item()\n",
    "        else:\n",
    "            correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "def evaluate_model(model, loader, criterion):\n",
    "    \"\"\" Uruchamia inferencjÄ™ i zbiera wyniki (etykiety, predykcje, prawdopodobieÅ„stwa) \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            if DEVICE == \"cuda\":\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs, _ = model(imgs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            else:\n",
    "                outputs, _ = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            # PrawdopodobieÅ„stwo klasy 1 (stego)\n",
    "            p = F.softmax(outputs, dim=1)[:,1]\n",
    "            preds = outputs.argmax(1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            probs.extend(p.cpu().tolist())\n",
    "\n",
    "    y_pred = np.array(all_preds)\n",
    "    y_true = np.array(all_labels)\n",
    "    y_probs = np.array(probs)\n",
    "\n",
    "    # UÅ¼ywamy predykcji opartych na progu 0.5 dla wstÄ™pnej oceny\n",
    "    # Uwaga: dla koÅ„cowej metryki AUC/Accuracy to nie ma znaczenia, ale dla CM i F1 ma\n",
    "    return total_loss / len(loader), y_pred, y_true, y_probs\n",
    "\n",
    "def calculate_and_save_metrics(y_true, y_pred, y_probs, set_name, epoch_num, out_dir, threshold=0.5):\n",
    "    \"\"\" Oblicza i zapisuje peÅ‚en zestaw metryk ewaluacyjnych. \"\"\"\n",
    "    # UÅ¼ywamy progu do binarnej klasyfikacji\n",
    "    y_pred_thr = (y_probs >= threshold).astype(int)\n",
    "\n",
    "    # Ustawienie katalogu wyjÅ›ciowego\n",
    "    # JeÅ›li epoch_num jest None (ocena koÅ„cowa), uÅ¼yj nazwy zbioru\n",
    "    if epoch_num is not None:\n",
    "        epoch_dir = out_dir / f\"epoch_{epoch_num:02d}_{set_name}_metrics\"\n",
    "    else:\n",
    "        epoch_dir = out_dir / f\"final_{set_name}_metrics\"\n",
    "\n",
    "    epoch_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_thr)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(cm, cmap='Blues')\n",
    "    title = f\"Confusion Matrix ({set_name}, Epoch {epoch_num or 'Final'})\"\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Pred\"); plt.ylabel(\"True\")\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j,i, str(cm[i,j]), ha='center', va='center',\n",
    "                     color='white' if cm[i,j]>cm.max()/2 else 'black')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(epoch_dir / \"confusion_matrix.png\"); plt.close()\n",
    "\n",
    "    # 2. ROC and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC Curve ({set_name}, Epoch {epoch_num or 'Final'})\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(epoch_dir / \"roc_curve.png\"); plt.close()\n",
    "\n",
    "    # 3. Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(recall, precision)\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"Precision-Recall ({set_name}, Epoch {epoch_num or 'Final'})\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(epoch_dir / \"pr_curve.png\"); plt.close()\n",
    "\n",
    "    # 4. Classification Report (JSON)\n",
    "    report = classification_report(y_true, y_pred_thr, output_dict=True)\n",
    "    with open(epoch_dir / \"classification_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(report, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred_thr)\n",
    "    return accuracy, roc_auc, report\n",
    "\n",
    "# ============================\n",
    "# ===== MAIN TRAINING LOOP ===\n",
    "# ============================\n",
    "train_hist = {\"loss\": [], \"acc\": [], \"val_loss\": [], \"val_acc\": [], \"val_auc\": []}\n",
    "best_val_acc = 0.0\n",
    "best_epoch = -1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    t0 = time.time()\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, use_mixup=USE_MIXUP)\n",
    "\n",
    "    # === EWENTRUALNE ZAPISYWANIE STATYSTYK WALIDACYJNYCH ===\n",
    "    val_loss, _, val_y_true, val_y_probs = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "    # â—ï¸ UÅ¼ywamy progu 0.5 dla spÃ³jnej metryki walidacyjnej w trakcie treningu\n",
    "    val_acc, val_auc, _ = calculate_and_save_metrics(\n",
    "        val_y_true, None, val_y_probs,\n",
    "        set_name=\"val\", epoch_num=epoch+1, out_dir=OUTPUT_DIR, threshold=0.5\n",
    "    )\n",
    "\n",
    "    scheduler.step(val_acc)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    # â—ï¸ WYÅšWIETLENIE ACCURACY I AUC\n",
    "    print(f\"TrainLoss={train_loss:.4f} TrainAcc={train_acc:.4f} | ValLoss={val_loss:.4f} ValAcc={val_acc:.4f} ValAUC={val_auc:.4f} | time={dt:.1f}s\")\n",
    "\n",
    "    train_hist[\"loss\"].append(train_loss)\n",
    "    train_hist[\"acc\"].append(train_acc)\n",
    "    train_hist[\"val_loss\"].append(val_loss)\n",
    "    train_hist[\"val_acc\"].append(val_acc)\n",
    "    train_hist[\"val_auc\"].append(val_auc) # Zapisujemy AUC\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), OUTPUT_DIR / \"best_stegnet.pth\")\n",
    "        print(\"âœ… Zapisano najlepsze wagi (CNN).\")\n",
    "\n",
    "print(f\"\\nNajlepszy ValAcc: {best_val_acc:.4f} (ep: {best_epoch+1})\")\n",
    "# wczytaj najlepsze wagi\n",
    "try:\n",
    "    model.load_state_dict(torch.load(OUTPUT_DIR / \"best_stegnet.pth\", map_location=DEVICE))\n",
    "except FileNotFoundError:\n",
    "    print(\"BÅ‚Ä…d: Nie znaleziono najlepszych wag. Kontynuacja z ostatnimi wagami.\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ===== EKSTRAKCJA CECH (TEST) =\n",
    "# ============================\n",
    "def extract_features_from_loader(model, loader):\n",
    "    model.eval()\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in tqdm(loader, desc=\"Extract\"):\n",
    "            imgs = imgs.to(DEVICE)\n",
    "\n",
    "            if DEVICE == \"cuda\":\n",
    "                with torch.cuda.amp.autocast(): # UÅ¼ycie autocast do ekstrakcji cech\n",
    "                    _, f = model(imgs)\n",
    "            else:\n",
    "                _, f = model(imgs)\n",
    "\n",
    "            feats.append(f.cpu().numpy())\n",
    "            labels.append(lbls.numpy())\n",
    "    feats = np.vstack(feats)\n",
    "    labels = np.concatenate(labels)\n",
    "    return feats, labels\n",
    "\n",
    "print(\"\\n--- RozpoczÄ™cie koÅ„cowej ewaluacji (CNN + SVM Ensemble) ---\")\n",
    "train_feats, train_lbls = extract_features_from_loader(model, train_loader)\n",
    "test_feats, test_lbls = extract_features_from_loader(model, test_loader)\n",
    "print(\"Feats shapes:\", train_feats.shape, test_feats.shape)\n",
    "\n",
    "# ============================\n",
    "# ===== SVM classifier (TEST) =======\n",
    "# ============================\n",
    "svm = SVC(kernel='rbf', probability=True, C=SVM_C, gamma='scale', random_state=SEED)\n",
    "svm.fit(train_feats, train_lbls)\n",
    "svm_probs = svm.predict_proba(test_feats)[:,1]\n",
    "\n",
    "# also CNN probs\n",
    "def cnn_predict_probs(model, loader):\n",
    "    model.eval()\n",
    "    probs, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in tqdm(loader, desc=\"CNN predict\"):\n",
    "            imgs = imgs.to(DEVICE)\n",
    "\n",
    "            if DEVICE == \"cuda\":\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs, _ = model(imgs)\n",
    "            else:\n",
    "                outputs, _ = model(imgs)\n",
    "\n",
    "            p = F.softmax(outputs, dim=1)[:,1]\n",
    "            probs.append(p.cpu().numpy())\n",
    "            labels.append(lbls.numpy())\n",
    "    return np.concatenate(probs), np.concatenate(labels)\n",
    "\n",
    "cnn_probs, y_true = cnn_predict_probs(model, test_loader)\n",
    "\n",
    "# simple ensemble: average prob\n",
    "ensemble_probs = (cnn_probs + svm_probs) / 2.0\n",
    "\n",
    "# best threshold by F1\n",
    "best_thr, best_f1 = 0.5, 0.0\n",
    "for thr in np.linspace(0.1,0.9,81):\n",
    "    preds = (ensemble_probs >= thr).astype(int)\n",
    "    f1 = f1_score(y_true, preds)\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_thr = f1, thr\n",
    "print(f\"Najlepszy prÃ³g (na zbiorze testowym): {best_thr:.3f}, F1: {best_f1:.3f}\")\n",
    "\n",
    "final_preds = (ensemble_probs >= best_thr).astype(int)\n",
    "\n",
    "# save models\n",
    "joblib.dump(svm, OUTPUT_DIR / \"svm_stegano.pkl\")\n",
    "torch.save(model.state_dict(), OUTPUT_DIR / \"best_stegnet_final.pth\")\n",
    "print(\"âœ… Zapisano modele w:\", OUTPUT_DIR)\n",
    "\n",
    "# ============================\n",
    "# ===== WIZUALIZACJE KOÅƒCOWE (TEST) =========\n",
    "# ============================\n",
    "def save_plot_history(hist, out_dir):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(hist['loss'], label='Train loss')\n",
    "    plt.plot(hist['val_loss'], label='Val loss')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(out_dir / \"loss_history.png\"); plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(hist['acc'], label='Train acc')\n",
    "    plt.plot(hist['val_acc'], label='Val acc')\n",
    "    plt.plot(hist['val_auc'], label='Val AUC') # Dodano AUC do historii\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Metric Value'); plt.title('Accuracy and AUC History')\n",
    "    plt.legend(); plt.grid(True)\n",
    "    plt.savefig(out_dir / \"acc_auc_history.png\"); plt.close()\n",
    "\n",
    "save_plot_history(train_hist, OUTPUT_DIR)\n",
    "\n",
    "# Zapisanie koÅ„cowych metryk na zbiorze testowym (Ensemble)\n",
    "final_test_acc, final_test_auc, final_report = calculate_and_save_metrics(\n",
    "    y_true, final_preds, ensemble_probs,\n",
    "    set_name=\"test_ensemble\", epoch_num=None, out_dir=OUTPUT_DIR, threshold=best_thr\n",
    ")\n",
    "\n",
    "print(\"--- KOÅƒCOWY RAPORT EWALUACYJNY (TEST SET, ENSEMBLE) ---\")\n",
    "print(f\"Accuracy: {final_test_acc:.4f}, AUC: {final_test_auc:.4f}, Threshold: {best_thr:.3f}\")\n",
    "print(\"Wszystkie statystyki zapisano w:\", OUTPUT_DIR / \"final_test_ensemble_metrics\")\n",
    "\n",
    "# ============================\n",
    "# ====== PRZYKÅADOWE PREDYKCJE =\n",
    "# ============================\n",
    "def show_examples(model, svm, dataset_subset, best_thr, n_examples=8, out_dir=OUTPUT_DIR):\n",
    "    model.eval()\n",
    "    idxs = random.sample(range(len(dataset_subset)), min(n_examples, len(dataset_subset)))\n",
    "    fig, axes = plt.subplots(2, math.ceil(n_examples/2), figsize=(16,8))\n",
    "    axes = axes.flatten()\n",
    "    for i, ix in enumerate(idxs):\n",
    "        img_tensor, label = dataset_subset[ix]\n",
    "        # img_tensor is normalized; undo normalization for display\n",
    "        img = img_tensor.cpu().numpy().transpose(1,2,0)\n",
    "        mean = np.array([0.485,0.456,0.406]); std = np.array([0.229,0.224,0.225])\n",
    "        img = np.clip(img * std + mean, 0, 1)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        t = img_tensor.unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            if DEVICE == \"cuda\":\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    out, feats = model(t)\n",
    "            else:\n",
    "                out, feats = model(t)\n",
    "\n",
    "            cnn_p = float(F.softmax(out, dim=1)[:,1].cpu().numpy()[0])\n",
    "        svm_p = float(svm.predict_proba(feats.cpu().numpy())[:,1][0])\n",
    "        ensemble_p = (cnn_p + svm_p) / 2.0\n",
    "        pred_label = \"stegano\" if ensemble_p >= best_thr else \"cover\"\n",
    "        true_label = \"stegano\" if label==1 else \"cover\"\n",
    "        axes[i].set_title(f\"Prawda:{true_label}\\nPred:{pred_label} ({ensemble_p:.2f})\\nCNN:{cnn_p:.2f} SVM:{svm_p:.2f}\", fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_dir / \"examples_predictions.png\")\n",
    "    plt.close()\n",
    "\n",
    "show_examples(model, svm, test_ds, best_thr=best_thr, n_examples=8, out_dir=OUTPUT_DIR)\n",
    "print(\"âœ… Zapisano przykÅ‚adowe predykcje.\")\n",
    "print(\"Koniec. Wyniki zapisane w folderze:\", OUTPUT_DIR)\n",
    "# ============================\n",
    "# ====== KONIEC PLIKU =======\n",
    "# ============================"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
